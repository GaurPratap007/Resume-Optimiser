{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GAURAV CHAUHAN\n",
      "Data Analyst\n",
      "\\+91 7065568441 ⋄gaurav.chauhan180303@gmail.com\n",
      "EDUCATION\n",
      "Bachelor of Technology in CSE (Core)\n",
      "2021 \\- 2025\n",
      "Vellore Institute of Technology, Vellore. CGPA : 8\\.88/10\n",
      "CBSE, Class XII\n",
      "2019 \\- 2020\n",
      "Kendriya Vidyalaya No.1, AFS Hindan, Ghaziabad, 91\\.6%\n",
      "CBSE, Class X\n",
      "2017 \\- 2018\n",
      "Kendriya Vidyalaya No.1, AFS Hindan, Ghaziabad, 93\\.8%\n",
      "SKILLS AND INTERESTS\n",
      "Programming Skills\n",
      "Python, C\\+\\+, JavaScript\n",
      "Data Analysis\n",
      "Pandas, NumPy, Excel (Advanced), SQL\n",
      "Data Visualization\n",
      "Tableau, Power BI, Matplotlib, Seaborn\n",
      "Statistical Analysis\n",
      "Regression Analysis, ARIMA, Time Series Forecasting, ANOVA\n",
      "Machine Learning\n",
      "Scikit\\-learn, TensorFlow, Keras, LSTM, Random Forest\n",
      "Database Management\n",
      "SQL, MySQL, MongoDB, Data Warehousing, ETL Processes\n",
      "Data Integration\n",
      "OpenWeatherMap API, REST APIs, Data Scraping (BeautifulSoup, Selenium)\n",
      "CRM\n",
      "HubSpot CRM, Shopify Flow, Google Analytics\n",
      "PROJECTS\n",
      "Real\\-Time Prediction of Power Generation from Wind Turbines using APIs\n",
      "Sep ’24 \\- Nov ’24\n",
      "Major Project\n",
      "· Developed a machine learning pipeline to predict energy output based on wind conditions, improving prediction\n",
      "accuracy by 18%.\n",
      "· Utilized APIs like OpenWeatherMap to collect real\\-time data and created a GUI dashboard for 24\\-hour predictions.\n",
      "· Tools: Python, Scikit\\-learn, TensorFlow, OpenWeatherMap API.\n",
      "E\\-Commerce Store for Pet Products and Services\n",
      "Aug ’24 \\- Nov ’24\n",
      "Internship project\n",
      "· Designed and developed a Shopify store for a client selling books and pet accessories.\n",
      "· Integrated a form to capture pet details (breed, size, travel preferences) for personalized recommendations.\n",
      "· Implemented SEO strategies, improving store visibility by 20%.\n",
      "· Tools: Shopify, HubSpot CRM, SEO, Google Maps API, Yelp API.\n",
      "Football Match Outcome Prediction Project\n",
      "April ’24\n",
      "Portfolio Project\n",
      "· Developed a predictive model using historical match data, achieving a 15% improvement in accuracy.\n",
      "· Analyzed over 1,000 matches and addressed missing data to enhance predictive reliability.\n",
      "· Tools: Python, Pandas, Tableau.\n",
      "\n",
      "INTERNSHIP\n",
      "Website Administrator Intern\n",
      "Aug ’24 \\- Oct ’24\n",
      "Shen Stark\n",
      "• Assisted in building and launching a pet\\-friendly travel store, enhancing user experience and personalizing\n",
      "recommendations.\n",
      "• Conducted research on over 50 pet\\-friendly services, improving conversions by 22%.\n",
      "• Implemented a pet form for breed and travel preferences, reducing drop\\-offs by 18%.\n",
      "• Tools: Shopify, Google Maps API, BringFido API, Custom Forms.\n",
      "Web Development Intern\n",
      "May ’23 \\- July ’23\n",
      "Khatte Meethe Desires\n",
      "• Created a Shopify store for candles, boosting organic traffic by 40% through SEO optimizations.\n",
      "• Managed a catalog of over 70 unique products and enhanced checkout processes, increasing monthly sales\n",
      "by 15%.\n",
      "• Integrated secure payment gateways, enhancing customer experience.\n",
      "POSITION OF RESPONSIBILITY\n",
      "\\- Head Boy, Kendriya Vidyalaya No.1\n",
      "2019 \\- 2020\n",
      "\\- Team Lead – Wind Power Prediction Project\n",
      "Sep ’24 \\- Nov ’24\n",
      "CERTIFICATIONS\n",
      "Google Cloud Digital Leader\n",
      "Dec ’23\n",
      "Google Cloud Foundations\n",
      "Dec ’23\n",
      "Supervised Machine Learning: Regression and Classification\n",
      "Sep ’24\n",
      "Advanced Learning Algorithms\n",
      "Sep ’24\n",
      "Python for Data Science, AI \\& Development\n",
      "Nov ’23\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from markdownify import markdownify as md\n",
    "\n",
    "def pdf_to_markdown(pdf_path):\n",
    "    # Open PDF file\n",
    "    doc = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    \n",
    "    # Extract text from each page\n",
    "    for page in doc:\n",
    "        text += page.get_text(\"text\") + \"\\n\"\n",
    "    \n",
    "    # Convert extracted text to markdown\n",
    "    markdown_resume = md(text)\n",
    "    return markdown_resume\n",
    "\n",
    "# Example usage\n",
    "pdf_path = \"Analyst_v2.pdf\"\n",
    "markdown_resume = pdf_to_markdown(pdf_path)\n",
    "print(markdown_resume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# Initialize the OpenAI client with your API key\n",
    "client = OpenAI(api_key='API_KEY')\n",
    "\n",
    "def optimize_resume(markdown_resume, job_description):\n",
    "    # Define the single prompt message\n",
    "    prompt = f\"\"\"\n",
    "    Here is a resume in markdown format:\n",
    "\n",
    "    {markdown_resume}\n",
    "\n",
    "    Here is the job description:\n",
    "\n",
    "    {job_description}\n",
    "\n",
    "    Please revise the resume so it highlights the skills, achievements, and experiences that match the job description.\n",
    "    \"\"\"\n",
    "\n",
    "    # Send the prompt as a single message to the ChatCompletion endpoint\n",
    "    response = client.completions.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,  # Directly use the prompt as a string, not as a list\n",
    "        max_tokens=1500,\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    optimized_resume = response['choices'][0]['text'].strip()  # Adjust to access 'text' instead of 'message'\n",
    "    return optimized_resume\n",
    "\n",
    "# Example usage\n",
    "job_description = \"Your job description here.\"\n",
    "markdown_resume = \"Your markdown resume here.\"\n",
    "optimized_resume = optimize_resume(markdown_resume, job_description)\n",
    "print(optimized_resume)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfkit\n",
    "import markdown2\n",
    "\n",
    "def markdown_to_pdf(markdown_text, output_pdf_path):\n",
    "    # Convert markdown to HTML\n",
    "    html = markdown2.markdown(markdown_text)\n",
    "    \n",
    "    # Convert HTML to PDF\n",
    "    pdfkit.from_string(html, output_pdf_path)\n",
    "\n",
    "# Example usage\n",
    "output_pdf_path = \"optimized_resume.pdf\"\n",
    "markdown_to_pdf(optimized_resume, output_pdf_path)\n",
    "print(f\"PDF saved to {output_pdf_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
